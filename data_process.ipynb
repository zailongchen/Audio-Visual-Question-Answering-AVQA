{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3962fa-a682-43a4-a2bc-f563e8a5c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import transforms, utils\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "import time\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "import multiprocessing\n",
    "from einops import rearrange\n",
    "import utils_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8caf431-c896-47a9-9155-ce60d5b548a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 1, 112, 112)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.load('/data/avst/10f_video_2plus1/00000002.npy')\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb208b-adb2-4351-9cd1-40657094f39a",
   "metadata": {},
   "source": [
    "# 将原始60帧的视频均匀采样10帧并保存，以便模型读取数据和训练时更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84916ab3-2472-4504-862d-c2cb875e376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformImage(img):\n",
    "\n",
    "    transform_list = []\n",
    "    mean = [0.43216, 0.394666, 0.37645]\n",
    "    std = [0.22803, 0.22145, 0.216989]\n",
    "    \n",
    "    transform_list.append(transforms.ToPILImage())\n",
    "    transform_list.append(transforms.Resize([224,224]))\n",
    "    transform_list.append(transforms.ToTensor())\n",
    "    transform_list.append(transforms.Normalize(mean, std))\n",
    "    trans = transforms.Compose(transform_list)\n",
    "    frame_tensor = trans(img)\n",
    "    \n",
    "    return frame_tensor\n",
    "\n",
    "def applyParallel(video_list, func):\n",
    "    ret = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(video) for video in tqdm(video_list))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced9cb4b-acfd-4c5a-beb1-3744d2797fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feats_res18(video):\n",
    "    C, H, W = 3, 224, 224\n",
    "    # for video in video_list:\n",
    "    s = time.time()\n",
    "    # save file\n",
    "    outfile = os.path.join(params['output_dir'], video + '.npy')\n",
    "    if os.path.exists(outfile):\n",
    "        # print(video, \" is already processed!\")\n",
    "        return 0\n",
    "\n",
    "    dst = video\n",
    "    # print(video)\n",
    "    if video == '.DS_Store':\n",
    "        return 0\n",
    "    # print(\"\\n-->: \", video)\n",
    "\n",
    "    image_list = sorted(glob.glob(os.path.join(params['video_path'], dst, '*.jpg')))\n",
    "    # print(len(image_list))\n",
    "    image_list = image_list[::params['n_frame_steps']]\n",
    "    image_list = image_list[:params['n_frames']]\n",
    "    # print(\"image_list: \", len(image_list))\n",
    "    images = torch.zeros((len(image_list), C, H, W))\n",
    "    # print(type(images))\n",
    "    for iImg in range(len(image_list)):\n",
    "        img = cv2.imread(image_list[iImg])\n",
    "        images[iImg] = TransformImage(img)\n",
    "    # print(images.shape)\n",
    "    print('time consumption: ',time.time() - s)\n",
    "    np.save(outfile, images)\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc0d17c-4299-4ece-b6df-2a4df9f3911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feats_r2plus1d(video):\n",
    "    C, H, W = 3, 112, 112\n",
    "    # for video in video_list:\n",
    "    s = time.time()\n",
    "    # save file\n",
    "    outfile = os.path.join(params['output_dir'], video + '.npy')\n",
    "    if os.path.exists(outfile):\n",
    "        # print(video, \" is already processed!\")\n",
    "        return 0\n",
    "\n",
    "    dst = video\n",
    "    # print(video)\n",
    "    if video == '.DS_Store':\n",
    "        return 0\n",
    "    # print(\"\\n-->: \", video)\n",
    "\n",
    "    image_list = sorted(glob.glob(os.path.join(params['video_path'], dst, '*.jpg')))\n",
    "    # print(len(image_list))\n",
    "    image_list = image_list[::params['n_frame_steps']]\n",
    "    image_list = image_list[:params['n_frames']]\n",
    "    # print(\"image_list: \", len(image_list))\n",
    "    images = torch.zeros((len(image_list)//1, C, 1, H, W))\n",
    "    i = 0\n",
    "    for iImg in range(len(image_list)):\n",
    "        ii = i//1\n",
    "        img = load_img(image_list[iImg])\n",
    "        images[ii, :, i%1, :, :] = img\n",
    "        i += 1\n",
    "    # print(images.shape)\n",
    "    # print('time consumption: ',time.time() - s)\n",
    "    np.save(outfile, images)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d892a4-fca9-49aa-896e-4fdc723689c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9288/9288 [00:40<00:00, 231.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all videos have been processed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    params = {}\n",
    "    params['output_dir'] = '/data/avst/20f_video/'\n",
    "    params['video_path'] = '/data/avst/frames_1fps/'\n",
    "    params['n_frames'] = 20\n",
    "    params['n_frame_steps'] = 60 // params['n_frames']\n",
    "    print(params['n_frame_steps'])\n",
    "    load_img = utils_3D.LoadTransformImage()\n",
    "\n",
    "    # 进程池\n",
    "    if not os.path.isdir(params['output_dir']):\n",
    "        os.mkdir(params['output_dir'])\n",
    "    video_list = os.listdir(params['video_path'])\n",
    "    \n",
    "    result = applyParallel(video_list, extract_feats_res18)\n",
    "    # extract_featsbin(video_list)\n",
    "    print('all videos have been processed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afc59c0-3938-41cd-bf7a-18c88a5e082a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00000002.npy',\n",
       " '00000003.npy',\n",
       " '00000004.npy',\n",
       " '00000005.npy',\n",
       " '00000006.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visual_posi = np.load('/data/frames_1fps/20f_video/00000002.npy')\n",
    "import os\n",
    "# video_list = sorted(os.listdir('/data/avst/videos/'))\n",
    "frame_list = sorted(os.listdir('/data/avst/r2plus1d_18/'))\n",
    "print(len(frame_list))\n",
    "frame_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f57c49-a104-47ac-a524-424428f21966",
   "metadata": {},
   "source": [
    "# 从原始视频中固定抽取60帧并保存"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c335272c-7c75-4233-b2bf-107506bb5e8f",
   "metadata": {},
   "source": [
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def fun_avg(name,df):\n",
    "    temp = 1\n",
    "    return temp\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    ret = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(name,group) for name, group in tqdm(dfGrouped))\n",
    "    return pd.concat(ret)\n",
    "    \n",
    "result = applyParallel(data1_temp2.groupby('name'), fun_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a95b93-57ab-4639-8c3a-4c6f5e189796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from torchvision import transforms, utils\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "import time\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "import multiprocessing\n",
    "import os\n",
    "from imageio import imsave\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22bc898a-fb05-4ade-a448-fb7749af0de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_generate(out_path, dst=60):\n",
    "    if not os.path.exists(out_path):\n",
    "        return False\n",
    "    folder_list = os.listdir(out_path)\n",
    "    jpg_number = 0\n",
    "    for file_name in folder_list:\n",
    "        if file_name.strip().lower().endswith('.jpg'):\n",
    "            jpg_number += 1\n",
    "    return jpg_number >= dst\n",
    "\n",
    "\n",
    "def fixed_video(clip, video_len_pre):\n",
    "    if clip.duration >= video_len_pre:\n",
    "        return clip\n",
    "    t_start = int(clip.duration)\n",
    "    if t_start == clip.duration:\n",
    "        t_start = -1\n",
    "    last_clip = clip.subclip(t_start)\n",
    "    final_clip = clip\n",
    "    while final_clip.duration < video_len_pre:\n",
    "        final_clip = concatenate_videoclips([final_clip, last_clip])\n",
    "    return final_clip\n",
    "\n",
    "\n",
    "def read_frame(reader, pos):\n",
    "    if not reader.proc:\n",
    "        reader.initialize()\n",
    "        reader.pos = pos\n",
    "        reader.lastread = reader.read_frame()\n",
    "\n",
    "    if pos == reader.pos:\n",
    "        return reader.lastread\n",
    "    elif (pos < reader.pos) or (pos > reader.pos + 100):\n",
    "        reader.initialize()\n",
    "        reader.pos = pos\n",
    "    else:\n",
    "        reader.skip_frames(pos - reader.pos - 1)\n",
    "    result = reader.read_frame()\n",
    "    reader.pos = pos\n",
    "    return result\n",
    "\n",
    "def compute_numbers(outpath): \n",
    "    folder_list = os.listdir(outpath)\n",
    "    folder_list.sort()\n",
    "\n",
    "    jpg_number = 0\n",
    "    pkl_number = 0\n",
    "    for file_name in folder_list:\n",
    "        if os.path.splitext(file_name)[-1].lower() == \".jpg\":\n",
    "            jpg_number += 1\n",
    "        if os.path.splitext(file_name)[-1].lower() == \".pkl\":\n",
    "            pkl_number += 1\n",
    "\n",
    "    if jpg_number != 10 or pkl_number != 10:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a50e85-45c5-4a57-a3ab-631cf37ed11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_video(video_file, out_path, fix_second, fps_count):\n",
    "    start = time.time()\n",
    "    # total_temp = compute_numbers(out_path)\n",
    "    total_temp = 1\n",
    "    if total_temp == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        try:\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "            if not os.path.isfile(video_file):\n",
    "                print(\"deal video error, %s is not a file\", video_file)\n",
    "                return 0\n",
    "            with VideoFileClip(video_file) as clip:\n",
    "                step = 1\n",
    "\n",
    "                reader = clip.reader\n",
    "                fps = clip.reader.fps\n",
    "                total_frames = reader.nframes\n",
    "\n",
    "                last_frames = int(total_frames % fps)\n",
    "\n",
    "                if last_frames == 0:\n",
    "                    last_frames = int(fps)\n",
    "                last_start = total_frames - last_frames\n",
    "\n",
    "\n",
    "                save_frame_index_arr = []\n",
    "\n",
    "                video_len_pre = fix_second\n",
    "                if fix_second == 0:\n",
    "                    video_len_pre = round(total_frames/fps)\n",
    "\n",
    "                video_len_pre = video_len_pre * fps_count\n",
    "\n",
    "                for i in range(video_len_pre):\n",
    "                    absolute_frame_pos = round((1 / (2*fps_count) + i / fps_count) * fps)\n",
    "\n",
    "                    if absolute_frame_pos > total_frames:\n",
    "                        relative_frame_pos = last_start + 1 + ((absolute_frame_pos - last_start - 1) % last_frames)\n",
    "                    else:\n",
    "                        relative_frame_pos = absolute_frame_pos\n",
    "\n",
    "                    save_frame_index_arr.append(relative_frame_pos)\n",
    "\n",
    "                save_frame_map = {}\n",
    "                loop_arr = list(set(save_frame_index_arr))\n",
    "                loop_arr.sort()\n",
    "                for i in loop_arr:\n",
    "                    if i not in save_frame_map:\n",
    "                        im = read_frame(reader, i)\n",
    "                        save_frame_map[i] = im\n",
    "\n",
    "                for i in range(len(save_frame_index_arr)):\n",
    "                    try:\n",
    "                        out_file_name = os.path.join(out_path, \"{:08d}.jpg\".format(i + 1))\n",
    "                        im = save_frame_map[save_frame_index_arr[i]]\n",
    "                        imsave(out_file_name, im)\n",
    "                    except Exception as e:\n",
    "                        print(\"(%s) save frame(%s) error\", video_file, str(i + 1), e)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"deal video(%s) error\", video_file, e)\n",
    "    print('time_consumption: ', time.time() - start)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6302bf03-171f-4920-bdfb-c68b4d03c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir_path_class(video_file):\n",
    "    name, ext = os.path.splitext(video_file)\n",
    "    out_path = os.path.join(param[\"dst_path_class\"], name)\n",
    "    if os.path.exists(out_path) and is_generate(out_path):\n",
    "        # print(\"Progress: \", \" ------- id: \", video_file, \" is already extracted!\")\n",
    "        return 0\n",
    "    else:\n",
    "        flag = deal_video(os.path.join(param[\"dir_path_class\"], video_file), out_path, param[\"fix_second\"], param[\"fps_count\"])\n",
    "    if flag == 1:\n",
    "        lgt = len(os.listdir(out_path))\n",
    "        print(\"Progress: \", \" ------- id: \", video_file, 'length of video is :',lgt)\n",
    "\n",
    "\n",
    "def applyParallel(video_list, func, num_process):\n",
    "    ret = Parallel(n_jobs=num_process)(delayed(func)(video) for video in tqdm(video_list))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11be43-fd74-4c97-bf47-a1203580956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    param = {}\n",
    "    param[\"dir_path_class\"] = '/data/avst/videos/'\n",
    "    param[\"dst_path_class\"] = '/data/avst/frames/'\n",
    "    param[\"fix_second\"] = 0\n",
    "    param[\"fps_count\"] = 1\n",
    "    \n",
    "    video_files = os.listdir(param[\"dir_path_class\"])\n",
    "    num_process = 10\n",
    "    # num_process = multiprocessing.cpu_count()\n",
    "    # video_files.sort()\n",
    "    result = applyParallel(video_files, process_dir_path_class, num_process)\n",
    "    print('all videos have been processed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe4373d-6417-489a-b383-11f4bd9b7a10",
   "metadata": {},
   "source": [
    "# pdf 2 png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4080fe81-dd65-4727-a32f-eacf5638f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fitz\n",
    "from reportlab.lib.pagesizes import portrait\n",
    "from reportlab.pdfgen import canvas\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cd4bf-387c-4aca-bf91-b7638b3dd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf2img(filename):\n",
    "\t#  打开PDF文件，生成一个对象\n",
    "\tdoc = fitz.open(filename)\n",
    "\tprint(\"共\",doc.pageCount,\"页\")\n",
    "\tfor pg in range(doc.pageCount):\n",
    "\t\tprint(\"\\r转换为图片\",pg+1,\"/\",doc.pageCount,end=\"\")\n",
    "\t\tpage = doc[pg]\n",
    "\t\trotate = int(0)\n",
    "\t\t# 每个尺寸的缩放系数为8，这将为我们生成分辨率提高64倍的图像。一般设为2\n",
    "\t\tzoom_x = 8.0\n",
    "\t\tzoom_y = 8.0\n",
    "\t\ttrans = fitz.Matrix(zoom_x, zoom_y).preRotate(rotate)\n",
    "\t\tpm = page.getPixmap(matrix=trans, alpha=False)\n",
    "\t\tpm.writePNG(filename+'_tu'+'{:02}.png' .format(pg))\n",
    "\tprint('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce5459-b360-4611-ba4b-b88503292253",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    filename='AVQA.pdf'\n",
    "    pdf2img(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czl",
   "language": "python",
   "name": "czl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
