{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3962fa-a682-43a4-a2bc-f563e8a5c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import transforms, utils\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb208b-adb2-4351-9cd1-40657094f39a",
   "metadata": {},
   "source": [
    "# 将原始60帧的视频均匀采样10帧并保存，以便模型读取数据和训练时更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84916ab3-2472-4504-862d-c2cb875e376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformImage(img):\n",
    "\n",
    "    transform_list = []\n",
    "    mean = [0.43216, 0.394666, 0.37645]\n",
    "    std = [0.22803, 0.22145, 0.216989]\n",
    "    \n",
    "    transform_list.append(transforms.ToPILImage())\n",
    "    transform_list.append(transforms.Resize([224,224]))\n",
    "    transform_list.append(transforms.ToTensor())\n",
    "    transform_list.append(transforms.Normalize(mean, std))\n",
    "    trans = transforms.Compose(transform_list)\n",
    "    frame_tensor = trans(img)\n",
    "    \n",
    "    return frame_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced9cb4b-acfd-4c5a-beb1-3744d2797fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feats(params):\n",
    "    C, H, W = 3, 224, 224\n",
    "    video_list = sorted(os.listdir(params['video_path']))\n",
    "    output_dir = os.path.join(os.getcwd(), params['output_dir'])\n",
    "    print(output_dir)\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    nn = 0\n",
    "    total_len = len(video_list)\n",
    "    print('total_len: ', total_len)\n",
    "    for video in tqdm(video_list):\n",
    "        # save file\n",
    "        outfile = os.path.join(output_dir, video + '.npy')\n",
    "        if os.path.exists(outfile):\n",
    "            print(video, \" is already processed!\")\n",
    "            continue\n",
    "\n",
    "        nn = nn + 1\n",
    "        # if nn == 3:\n",
    "        #     break\n",
    "        dst = video\n",
    "        # print(video)\n",
    "        if video == '.DS_Store':\n",
    "            continue\n",
    "        # print(\"\\n-->: \", video)\n",
    "\n",
    "        image_list = sorted(glob.glob(os.path.join(params['video_path'], dst, '*.jpg')))\n",
    "        # print(\"len(image_list): \", len(image_list))\n",
    "        samples = np.round(np.linspace(0, len(image_list) - 1, params['n_frame_steps']))\n",
    "        # print(samples)\n",
    "        image_list = [image_list[int(sample)] for sample in samples]\n",
    "        # print(\"image_list len: \", len(image_list))\n",
    "        images = torch.zeros((len(image_list), C, H, W))\n",
    "        # print(type(images))\n",
    "        s = time.time()\n",
    "        for iImg in range(len(image_list)):\n",
    "            img = cv2.imread(image_list[iImg])\n",
    "            images[iImg] = TransformImage(img)\n",
    "        # print(images.shape)\n",
    "        # print('time consumption: ',time.time() - s)\n",
    "        np.save(outfile, images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d892a4-fca9-49aa-896e-4fdc723689c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/frames_1fps/10f_video/\n",
      "total_len:  9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000002  is already processed!\n",
      "00000003  is already processed!\n",
      "00000004  is already processed!\n",
      "00000005  is already processed!\n",
      "00000006  is already processed!\n",
      "00000007  is already processed!\n",
      "00000008  is already processed!\n",
      "00000009  is already processed!\n",
      "00000012  is already processed!\n",
      "00000014  is already processed!\n",
      "00000015  is already processed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9288/9288 [1:46:45<00:00,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all videos have been processed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['model'] = 'resnet18'\n",
    "params['output_dir'] = '/data/frames_1fps/10f_video/'\n",
    "params['video_path'] = './data/feats/frames_1fps/'\n",
    "params['n_frame_steps'] = 10\n",
    "\n",
    "extract_feats(params)\n",
    "print('all videos have been processed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1afc59c0-3938-41cd-bf7a-18c88a5e082a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "visual_posi = np.load('/data/frames_1fps/10f_video/00000002.npy')\n",
    "print(type(visual_posi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ce019-f9eb-48a5-b15f-94fea0b5dd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czl",
   "language": "python",
   "name": "czl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
