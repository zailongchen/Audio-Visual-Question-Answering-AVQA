nohup: ignoring input
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
INFO:root:********************************************************
INFO:root:****************** Experiment setting ******************
INFO:root:label_train dir --------- ./data/json_update/avqa-train.json
INFO:root:label_val dir ----------- ./data/json_update/avqa-val.json
INFO:root:label_test dir ---------- ./data/json_update/avqa-test.json
INFO:root:audio dir --------------- ./data/feats/vggish
INFO:root:posi_video dir ---------- /data/avst/r2plus1d_18/
INFO:root:nega_video dir ---------- /data/avst/r2plus1d_18/
INFO:root:batch size -------------- 32
INFO:root:num of epoches ---------- 15
INFO:root:learning rate ----------- 0.0001
INFO:root:name of model ----------- AVQA_Fusion_Net
INFO:root:train or test ----------- train
INFO:root:model save dir ---------- ./data/checkpoints/checkpoint_0.3loc
INFO:root:num of dataloader workers 2
INFO:root:gpu id ------------------ 0,1,2,3
INFO:root:********************************************************
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:root:------------ Audio-Visual Spatial-Temporal Model ------------ 

INFO:root:-------------- training dataset preparation --------------

INFO:root:--------- training dataset preparation completed ----------

INFO:root:length of training dataset ----------- 250

INFO:root:-------------- validation dataset preparation --------------

INFO:root:-------- validation dataset preparation completed ----------
INFO:root:length of validation dataset ----------- 143
INFO:root:-------------- start training --------------

/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
INFO:root:Train Epoch: 1 [0/31927 ]	Loss: 5.204539775848389
INFO:root:Train Epoch: 1 [3200/31927 ]	Loss: 1.523552417755127
INFO:root:Train Epoch: 1 [6400/31927 ]	Loss: 1.33650541305542
INFO:root:Accuracy qa: 62.12784588441331
INFO:root:Train Epoch: 2 [0/31927 ]	Loss: 1.163567066192627
INFO:root:Train Epoch: 2 [3200/31927 ]	Loss: 1.3135817050933838
INFO:root:Train Epoch: 2 [6400/31927 ]	Loss: 1.2430660724639893
INFO:root:Accuracy qa: 65.28021015761821
INFO:root:Train Epoch: 3 [0/31927 ]	Loss: 1.1119956970214844
INFO:root:Train Epoch: 3 [3200/31927 ]	Loss: 1.1062133312225342
INFO:root:Train Epoch: 3 [6400/31927 ]	Loss: 1.1376606225967407
INFO:root:Accuracy qa: 67.6444833625219
INFO:root:Train Epoch: 4 [0/31927 ]	Loss: 0.9680922031402588
INFO:root:Train Epoch: 4 [3200/31927 ]	Loss: 0.9736391305923462
INFO:root:Train Epoch: 4 [6400/31927 ]	Loss: 0.8946400284767151
INFO:root:Accuracy qa: 69.11120840630473
INFO:root:Train Epoch: 5 [0/31927 ]	Loss: 0.8514086604118347
INFO:root:Train Epoch: 5 [3200/31927 ]	Loss: 0.7789329886436462
INFO:root:Train Epoch: 5 [6400/31927 ]	Loss: 0.7781235575675964
INFO:root:Accuracy qa: 70.00875656742556
INFO:root:Train Epoch: 6 [0/31927 ]	Loss: 0.9578735828399658
INFO:root:Train Epoch: 6 [3200/31927 ]	Loss: 0.8223956227302551
INFO:root:Train Epoch: 6 [6400/31927 ]	Loss: 0.779280960559845
INFO:root:Accuracy qa: 71.2784588441331
INFO:root:Train Epoch: 7 [0/31927 ]	Loss: 0.8387973308563232
INFO:root:Train Epoch: 7 [3200/31927 ]	Loss: 0.7471688985824585
INFO:root:Train Epoch: 7 [6400/31927 ]	Loss: 0.6787334680557251
INFO:root:Accuracy qa: 69.63660245183888
INFO:root:Train Epoch: 8 [0/31927 ]	Loss: 0.541999101638794
INFO:root:Train Epoch: 8 [3200/31927 ]	Loss: 0.5570647120475769
INFO:root:Train Epoch: 8 [6400/31927 ]	Loss: 0.6365078687667847
INFO:root:Accuracy qa: 72.21978984238179
INFO:root:Train Epoch: 9 [0/31927 ]	Loss: 0.5577541589736938
INFO:root:Train Epoch: 9 [3200/31927 ]	Loss: 0.3879116475582123
INFO:root:Train Epoch: 9 [6400/31927 ]	Loss: 0.46369847655296326
INFO:root:Accuracy qa: 74.25569176882662
INFO:root:Train Epoch: 10 [0/31927 ]	Loss: 0.3801150321960449
INFO:root:Train Epoch: 10 [3200/31927 ]	Loss: 0.37485766410827637
INFO:root:Train Epoch: 10 [6400/31927 ]	Loss: 0.35083478689193726
INFO:root:Accuracy qa: 74.38704028021016
INFO:root:Train Epoch: 11 [0/31927 ]	Loss: 0.3613874912261963
INFO:root:Train Epoch: 11 [3200/31927 ]	Loss: 0.27838605642318726
INFO:root:Train Epoch: 11 [6400/31927 ]	Loss: 0.29583337903022766
INFO:root:Accuracy qa: 74.29947460595447
INFO:root:Train Epoch: 12 [0/31927 ]	Loss: 0.23572048544883728
INFO:root:Train Epoch: 12 [3200/31927 ]	Loss: 0.2959805727005005
INFO:root:Train Epoch: 12 [6400/31927 ]	Loss: 0.2790231704711914
INFO:root:Accuracy qa: 73.55516637478108
INFO:root:Train Epoch: 13 [0/31927 ]	Loss: 0.23335716128349304
INFO:root:Train Epoch: 13 [3200/31927 ]	Loss: 0.27440857887268066
INFO:root:Train Epoch: 13 [6400/31927 ]	Loss: 0.3049934506416321
INFO:root:Accuracy qa: 73.48949211908932
INFO:root:Train Epoch: 14 [0/31927 ]	Loss: 0.2294609397649765
INFO:root:Train Epoch: 14 [3200/31927 ]	Loss: 0.26299288868904114
INFO:root:Train Epoch: 14 [6400/31927 ]	Loss: 0.2065410614013672
INFO:root:Accuracy qa: 73.62084063047286
INFO:root:Train Epoch: 15 [0/31927 ]	Loss: 0.22098958492279053
INFO:root:Train Epoch: 15 [3200/31927 ]	Loss: 0.23454837501049042
INFO:root:Train Epoch: 15 [6400/31927 ]	Loss: 0.2505054473876953
INFO:root:Accuracy qa: 73.75218914185639
INFO:root:-------------- end of training --------------

Traceback (most recent call last):
  File "/home/jovyan/Bert/main_avst_loc_glo.py", line 360, in <module>
    main(args)
  File "/home/jovyan/Bert/main_avst_loc_glo.py", line 314, in main
    checkpoint = torch.load(os.path.join(args.model_save_dir, args.checkpoint, 'best' '.tar'))
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1049, in _load
    result = unpickler.load()
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1019, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1001, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/_utils.py", line 78, in _cuda
    return torch._UntypedStorage(self.size(), device=torch.device('cuda')).copy_(self, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "/home/jovyan/Bert/main_avst_loc_glo.py", line 360, in <module>
    main(args)
  File "/home/jovyan/Bert/main_avst_loc_glo.py", line 314, in main
    checkpoint = torch.load(os.path.join(args.model_save_dir, args.checkpoint, 'best' '.tar'))
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1049, in _load
    result = unpickler.load()
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1019, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1001, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/_utils.py", line 78, in _cuda
    return torch._UntypedStorage(self.size(), device=torch.device('cuda')).copy_(self, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "/home/jovyan/Bert/main_avst_loc_glo.py", line 360, in <module>
    main(args)
  File "/home/jovyan/Bert/main_avst_loc_glo.py", line 314, in main
    checkpoint = torch.load(os.path.join(args.model_save_dir, args.checkpoint, 'best' '.tar'))
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1049, in _load
    result = unpickler.load()
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1019, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 1001, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/_utils.py", line 78, in _cuda
    return torch._UntypedStorage(self.size(), device=torch.device('cuda')).copy_(self, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
INFO:root:length of test dataset ----------- 9129
INFO:root:-------------- loading checkpoint ----------------
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 5906 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 5907) of binary: /home/jovyan/conda-envs/czl/bin/python
Traceback (most recent call last):
  File "/home/jovyan/conda-envs/czl/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/jovyan/conda-envs/czl/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_avst_loc_glo.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2022-11-10_10:37:51
  host      : jupyter-chenzailong
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 5908)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2022-11-10_10:37:51
  host      : jupyter-chenzailong
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 5909)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2022-11-10_10:37:51
  host      : jupyter-chenzailong
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 5907)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
nohup: ignoring input
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
INFO:root:********************************************************
INFO:root:****************** Experiment setting ******************
INFO:root:label_train dir --------- ./data/json_update/avqa-train.json
INFO:root:label_val dir ----------- ./data/json_update/avqa-val.json
INFO:root:label_test dir ---------- ./data/json_update/avqa-test.json
INFO:root:audio dir --------------- ./data/feats/vggish
INFO:root:posi_video dir ---------- /data/avst/r2plus1d_18/
INFO:root:nega_video dir ---------- /data/avst/r2plus1d_18/
INFO:root:batch size -------------- 32
INFO:root:num of epoches ---------- 15
INFO:root:learning rate ----------- 0.0001
INFO:root:name of model ----------- AVQA_Fusion_Net
INFO:root:train or test ----------- test
INFO:root:model save dir ---------- ./data/checkpoints/checkpoint_0.3loc
INFO:root:num of dataloader workers 2
INFO:root:gpu id ------------------ 0,1,2,3
INFO:root:********************************************************
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO:root:------------ Audio-Visual Spatial-Temporal Model ------------ 

INFO:root:length of test dataset ----------- 9129
INFO:root:-------------- loading checkpoint ----------------
INFO:root:-------- checkpoint loading successfully ----------
INFO:root:********************************************************
INFO:root:the best epoch ---------- 10
INFO:root:the best train acc ------ 74.38704028021016
INFO:root:********************************************************
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/home/jovyan/conda-envs/czl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Audio Counting num: 843
Audio Cmp num: 415
Visual Counting num: 947
Visual Loc num: 956
AV Ext num: 804
AV counting num: 926
AV Loc num: 590
AV Cmp num: 721
AV Temporal num: 541
INFO:root:Audio Counting Accuracy: 82.89 %
INFO:root:Audio Cmp Accuracy: 69.87 %
INFO:root:Audio Accuracy: 78.09 %
INFO:root:Visual Counting Accuracy: 79.11 %
INFO:root:Visual Loc Accuracy: 78.04 %
INFO:root:Visual Accuracy: 78.57 %
INFO:root:AV Ext Accuracy: 81.38 %
INFO:root:AV counting Accuracy: 73.20 %
INFO:root:AV Loc Accuracy: 64.13 %
INFO:root:AV Cmp Accuracy: 65.49 %
INFO:root:AV Temporal Accuracy: 65.82 %
INFO:root:AV Accuracy: 70.29 %
INFO:root:Overall Accuracy: 73.86 %
Audio Counting num: 843
Audio Cmp num: 415
Visual Counting num: 947
Visual Loc num: 956
AV Ext num: 804
AV counting num: 926
AV Loc num: 590
AV Cmp num: 721
AV Temporal num: 541
